{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRF\n",
    "\n",
    "Ê®°ÂûãÂèÇËÄÉhttps://github.com/bojone/crf/\n",
    "\n",
    "CRFÂÆûÁé∞ÂèÇËÄÉhttps://github.com/bojone/crf/blob/master/crf_keras.py#L54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:45.503039Z",
     "start_time": "2020-03-22T10:13:45.487049Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import sys\n",
    "if __name__ == '__main__': sys.path.append('..')\n",
    "import exp.common as common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:45.520027Z",
     "start_time": "2020-03-22T10:13:45.506036Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "def print_gc(file=sys.stdout):\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "                print(type(obj), obj.size(), file=file)\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:45.542017Z",
     "start_time": "2020-03-22T10:13:45.524028Z"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "def pj(*args, **kargs):\n",
    "    if common.IN_JUPYTER:\n",
    "        pprint(*args, **kargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:45.750895Z",
     "start_time": "2020-03-22T10:13:45.545014Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import operator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:45.758891Z",
     "start_time": "2020-03-22T10:13:45.753894Z"
    }
   },
   "outputs": [],
   "source": [
    "#test_export\n",
    "def is_cuda():\n",
    "    return torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### READ Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:46.684133Z",
     "start_time": "2020-03-22T10:13:45.761889Z"
    }
   },
   "outputs": [],
   "source": [
    "#test_export\n",
    "import pandas as pd\n",
    "def read_data(Forever=False):\n",
    "    sent, tags = [],[]\n",
    "    con = True\n",
    "    while con:\n",
    "        with open('../data/CRF/ResumeNER/train.char.bmes', 'r', encoding='UTF-8') as f:\n",
    "            for line in f.readlines():\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    yield sent, tags\n",
    "                    sent, tags = [],[]\n",
    "                    continue\n",
    "\n",
    "                assert len(line.split())>=2, line\n",
    "                w, tag = line.split()\n",
    "                sent.append(w)\n",
    "                tags.append(tag)\n",
    "        con = Forever\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "# next(read_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:46.702169Z",
     "start_time": "2020-03-22T10:13:46.684133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {1:3}\n",
    "# d.items()\n",
    "dict(map(reversed, d.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:47.132394Z",
     "start_time": "2020-03-22T10:13:46.707163Z"
    }
   },
   "outputs": [],
   "source": [
    "#test_export\n",
    "import sure\n",
    "from collections import Counter\n",
    "\n",
    "# ÂáÜÂ§áÊï∞ÊçÆ\n",
    "# Counter return 0 for unknow key\n",
    "class C2ID(Counter):\n",
    "    \n",
    "    # 0 for unknow\n",
    "    def __init__(self):\n",
    "        super().__init__(self)\n",
    "        self.min_freq = 1\n",
    "        # 0 for unknow\n",
    "        self.indexer = 0\n",
    "        self.freq_cnt = Counter()\n",
    "        self._reverse_dict = {}\n",
    "    \n",
    "    def touchc(self, c):\n",
    "        self.freq_cnt[c] += 1\n",
    "        \n",
    "    def touchs(self, s):\n",
    "        for c in s:\n",
    "            self.touchc(c)\n",
    "    \n",
    "    def update_index(self):\n",
    "        for k,v in self.freq_cnt.items():\n",
    "            if v < self.min_freq: continue\n",
    "            if k in self: continue\n",
    "                \n",
    "            self._reverse_dict[self.indexer]=k\n",
    "            self[k] = self.indexer\n",
    "            \n",
    "            self.indexer += 1\n",
    "    \n",
    "    def reverse(self, idx):\n",
    "        return self._reverse_dict[idx]\n",
    "    \n",
    "    def reveres_list(self, list_idx):\n",
    "        return list(map(self.reverse, list_idx))\n",
    "            \n",
    "c2id = C2ID()\n",
    "tag2id = C2ID()\n",
    "# tag2id.indexer = 0\n",
    "UNK = 'UNK'\n",
    "PAD = 'PAD'\n",
    "for cv in [c2id, tag2id]:\n",
    "    cv.touchs([UNK, PAD])\n",
    "\n",
    "for sent, tags in read_data():\n",
    "    c2id.touchs(sent)\n",
    "    tag2id.touchs(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:47.146997Z",
     "start_time": "2020-03-22T10:13:47.132394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1794"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c2id.freq_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:47.498434Z",
     "start_time": "2020-03-22T10:13:47.149994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mxlen 178 65671\n"
     ]
    }
   ],
   "source": [
    "#test_export\n",
    "# token ÁöÑÂàÜÂ∏É\n",
    "\n",
    "def is_breaker(c,t):\n",
    "    if c2id[c] == 0:\n",
    "        if t[0] == 'B':return True\n",
    "        if t[0] == 'M':return True\n",
    "        if t[0] == 'S':return True\n",
    "    return False\n",
    "\n",
    "def check_breaker():\n",
    "    max_len = 0\n",
    "    breaker_c = []\n",
    "    for sent, tags in read_data():\n",
    "        max_len = max(len(sent), max_len)\n",
    "        for c, t in zip(sent, tags):\n",
    "            if is_breaker(c, t): breaker_c.append(c)\n",
    "    return max_len, breaker_c\n",
    "\n",
    "# sorted(c2id.freq_cnt.items(), key=operator.itemgetter(1))[:30]\n",
    "df = pd.DataFrame(c2id.freq_cnt.items())\n",
    "mxlen, breaker_c = check_breaker()\n",
    "\n",
    "# ÂÖà‰∏çËÄÉËôëÂéªÈô§‰ΩéÈ¢ëÈ°π\n",
    "c2id.update_index() # 0 for padding\n",
    "tag2id.update_index() # 0 for unknown char\n",
    "print('mxlen', mxlen, len(breaker_c))\n",
    "import pandas  as pd\n",
    "# df = df.sort_values(by=1)\n",
    "\n",
    "# df.describe()\n",
    "# c2id.min_freq = 2\n",
    "# c2id.update_index()\n",
    "# Ê£ÄÊü•ÊúâÊ≤°ÊúâÊâìÊñ≠Ê†áÁ≠æ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:47.532413Z",
     "start_time": "2020-03-22T10:13:47.501431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1794.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>69.175585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>280.915003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5141.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1\n",
       "count  1794.000000\n",
       "mean     69.175585\n",
       "std     280.915003\n",
       "min       1.000000\n",
       "25%       2.000000\n",
       "50%       6.000000\n",
       "75%      23.000000\n",
       "max    5141.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_export\n",
    "# token ÁöÑÂàÜÂ∏É\n",
    "import pandas  as pd\n",
    "sorted(c2id.freq_cnt.items(), key=operator.itemgetter(1))[:30]\n",
    "df = pd.DataFrame(c2id.freq_cnt.items())\n",
    "df = df.sort_values(by=1)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:47.575388Z",
     "start_time": "2020-03-22T10:13:47.535411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAD', 'B-NAME', 'E-NAME']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_export\n",
    "# tag ÁöÑÂàÜÂ∏É\n",
    "import pandas  as pd\n",
    "sorted(tag2id.freq_cnt.items(), key=operator.itemgetter(1))[:30]\n",
    "df = pd.DataFrame(tag2id.freq_cnt.items())\n",
    "# df = df.sort_values(by=1)\n",
    "# df.describe()\n",
    "df[ list(map(lambda x:x[0] == 'B' or x[0] == 'S', df[0]) )][1].sum()\n",
    "# df\n",
    "tag2id.reveres_list([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T03:30:43.154605Z",
     "start_time": "2020-03-11T03:30:43.150611Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "#### onehot and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:47.612368Z",
     "start_time": "2020-03-22T10:13:47.577387Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def padding(padding_idx,X):\n",
    "    X = list(X)\n",
    "    max_len = max(map(len, X))\n",
    "    for i,x in enumerate(X):\n",
    "        X[i] = x + [padding_idx] * (max_len - len(x))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:47.650345Z",
     "start_time": "2020-03-22T10:13:47.616378Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from torch import nn\n",
    "def onehot(y, dim_size):\n",
    "    \"\"\"\n",
    "    y: shape (batch_size, max_seq_len)\n",
    "    \"\"\"\n",
    "    assert len(y.shape) == 2, y.shape\n",
    "    eye = np.eye(dim_size)\n",
    "    return eye[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:48.122440Z",
     "start_time": "2020-03-22T10:13:47.652345Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                              | 0/1910 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 68), (2, 68)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1910"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_export\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "assert isinstance( math.ceil(0.3), int)\n",
    "\n",
    "class get_data():\n",
    "    def __init__(self, batch_size = 2):\n",
    "        self.batch_size = batch_size\n",
    "#         self.len = math.ceil( len(list(read_data()))/batch_size )\n",
    "        self.len = len(list(read_data()))//batch_size \n",
    "        \n",
    "    def __iter__(self):\n",
    "        batch_size = self.batch_size\n",
    "        cnt = 0\n",
    "        X = []\n",
    "        Y = []\n",
    "        def set_train():\n",
    "            a = padding(c2id[PAD]  , X)\n",
    "            b = padding(tag2id[PAD], Y)\n",
    "            return tuple(map( np.array, (a,b)))\n",
    "        \n",
    "        for x, y in read_data():\n",
    "            cnt += 1\n",
    "            X.append(list(map(  c2id.__getitem__, x)))\n",
    "            Y.append(list(map(tag2id.__getitem__, y)))\n",
    "    \n",
    "            if cnt == batch_size:\n",
    "                yield set_train()\n",
    "                \n",
    "                # clean up\n",
    "                cnt = 0\n",
    "                X = []\n",
    "                Y = []\n",
    "        \n",
    "        return set_train()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "for x in tqdm(get_data()):\n",
    "    break\n",
    "print(list(map(np.shape, x)))\n",
    "len(get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:48.136432Z",
     "start_time": "2020-03-22T10:13:48.125439Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]],\n",
       "\n",
       "       [[1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_export\n",
    "onehot(np.array(\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [0,3,1]\n",
    "    ]\n",
    "), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TopK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:48.168413Z",
     "start_time": "2020-03-22T10:13:48.139429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "import sure\n",
    "from queue import PriorityQueue\n",
    "class TopK:\n",
    "    def __init__(self, k, topks = None):\n",
    "        # (priority_number, data)\n",
    "#         pq = PriorityQueue(k)\n",
    "        assert k == 1, \"not implemented\"\n",
    "    \n",
    "        self.m_inf = -float('inf')\n",
    "        self.data = None\n",
    "        self.score = self.m_inf\n",
    "        \n",
    "        if topks is not None:\n",
    "            assert len(topks) >= k\n",
    "            for t in topks:\n",
    "                self.put( t.get_max_data(), t.get_max_score(),)\n",
    "            return \n",
    "    \n",
    "#         for i in range(k):\n",
    "#             pq.put_nowait((m_inf))\n",
    "#         self.pq = pq\n",
    "        \n",
    "    def put(self,  data, score,):\n",
    "        assert len(data) >= 1\n",
    "        if self.score is self.m_inf:\n",
    "            pass\n",
    "        else :\n",
    "            assert type(score) == type(self.score), \"score type muse consit\"\n",
    "        if score > self.score:\n",
    "            self.score, self.data = score, data\n",
    "    \n",
    "    def __str__(self):\n",
    "        return (self.score, self.data).__str__()\n",
    "    \n",
    "    def get_max_score(self):\n",
    "        return self.score\n",
    "    \n",
    "    def get_max_data(self):\n",
    "        return self.data\n",
    "    \n",
    "    def get_kth_data(self, k):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def get_kth_score(self, k):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "        \n",
    "    \n",
    "    \n",
    "topk = TopK(1)\n",
    "for i in range(10):\n",
    "    topk.put( [i],i+10,)\n",
    "#     print(topk.data)\n",
    "# assert topk.\n",
    "topk.get_max_data().should.eql([9])\n",
    "topk.get_max_score().should.eql(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:48.184404Z",
     "start_time": "2020-03-22T10:13:48.171410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_export\n",
    "topk = TopK(1)\n",
    "topk.put( [1], 1,)\n",
    "for i in range(1, 10):\n",
    "    t = list(range(i)) + topk.get_max_data()\n",
    "    topk.put(t, i)\n",
    "topk.m_inf.should.eql(topk.m_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:48.202395Z",
     "start_time": "2020-03-22T10:13:48.188401Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def viterbi(nodes,trans_p, initial_state = None, topk = 1, start_p = None):\n",
    "    \"\"\"\n",
    "    nodes: array, [{\"<TAG>\": <float>}]\n",
    "    trans_p: dict, {\"<TAG_A>\": {\"TAG_B\": <float>}}, TAG_A -> TAG-B\n",
    "    return_max=True: bool, set to False if your want to avoid ill endding tag and find your own.\n",
    "    initial_state=None: None or list to avoid impossible starting tags\n",
    "    start_p: P(o1), may be nessary\n",
    "    all float number in log form\n",
    "    \"\"\"\n",
    "    assert len(nodes.shape) == 2,len(nodes.shape)  # max_seq_len, label_num\n",
    "    kth = 1\n",
    "    if initial_state is None:\n",
    "        initial_state = nodes[0]\n",
    "        nodes = nodes[1:]\n",
    "        \n",
    "    def init_tok():return TopK(kth)\n",
    "    \n",
    "    def init_toks(): return [init_tok() for i in range(nodes.shape[-1])]\n",
    "\n",
    "    last_best_nodes = init_toks()\n",
    "    next_best_nodes = init_toks()\n",
    "    \n",
    "    \n",
    "    for idx, (tk,score) in enumerate( zip(last_best_nodes , initial_state)):\n",
    "        tk.put([idx], score)\n",
    "\n",
    "    for node in nodes:\n",
    "        for t,v in enumerate(node):\n",
    "\n",
    "            current_best_node = init_tok() # for t\n",
    "            \n",
    "            for topk in last_best_nodes:\n",
    "                path = topk.get_max_data()\n",
    "                score = topk.get_max_score()\n",
    "                \n",
    "                last_t = path[-1]\n",
    "                new_path = path + [t]\n",
    "                tran = trans_p[last_t][t]\n",
    "                \n",
    "                current_best_node.put(new_path, score + tran + v)\n",
    "\n",
    "            next_best_nodes[t] = current_best_node\n",
    "            \n",
    "        next_best_nodes, last_best_nodes =  last_best_nodes, next_best_nodes,\n",
    "        \n",
    "    topk = TopK(1, last_best_nodes)\n",
    "    \n",
    "    return topk.get_max_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:48.222382Z",
     "start_time": "2020-03-22T10:13:48.206391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_export\n",
    "nodes = [\n",
    "    [1, 2, 1],\n",
    "    [1, 1, 3],\n",
    "    [4, 1, 3],\n",
    "]\n",
    "trans = [\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1],\n",
    "]\n",
    "nodes, trans = map(np.array, [nodes, trans])\n",
    "viterbi(nodes, trans).should.eql([1,2,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get_shift_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:48.238373Z",
     "start_time": "2020-03-22T10:13:48.225380Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_shift_mask(labels):\n",
    "    \"\"\"\n",
    "    labels: (batch_size, max_seq_len, num_label) in onehot all element should be 1/0\n",
    "    turn num_labels into matrix of (num_label, num_label) where m[ y[i] ][ y[i+1] ] = 1, 0 for else\n",
    "    return (batch_size, max_seq_len, num_label, num_label)\n",
    "    \"\"\"\n",
    "    labels1 = labels[:, :-1, ] # y[i]\n",
    "\n",
    "    labels2 = labels[:, 1:] # y[i + 1]\n",
    "\n",
    "    labels1 = labels1[:, :, :, None] # as Á≥ªÊï∞, row indexer\n",
    "    labels2 = labels2[:, :, None, :] # as row, col indexer\n",
    "\n",
    "    shift_mask = labels1 * labels2\n",
    "    return shift_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:48.253364Z",
     "start_time": "2020-03-22T10:13:48.241371Z"
    }
   },
   "outputs": [],
   "source": [
    "#test_export\n",
    "import sure\n",
    "tmp_num_label = 5\n",
    "tmp_labels_raw = [[1,2,3,4], [3,3,3,2]]\n",
    "tmp_labels = np.array(tmp_labels_raw)\n",
    "tmp_labels = onehot(tmp_labels, tmp_num_label)\n",
    "shift_mask = get_shift_mask(tmp_labels)\n",
    "\n",
    "# for batch\n",
    "for tags, mask in zip(tmp_labels_raw, shift_mask):\n",
    "    \n",
    "    # for seq\n",
    "    # len = max_seq_len - 1\n",
    "    for y_i, y_j,matrix in zip(tags[:-1], tags[1:], mask):\n",
    "        # y_j  = y[i+1]\n",
    "        matrix = np.copy(matrix)\n",
    "        matrix[y_i][y_j] -= 1 # only matrix[y_i][y_j] = 1, else 0\n",
    "        matrix.sum().should.eql(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:48.278351Z",
     "start_time": "2020-03-22T10:13:48.259361Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import math\n",
    "# üë¥ÁöÑCRF\n",
    "class CRF(nn.Module):\n",
    "    def __init__(self, num_label):\n",
    "        super().__init__()\n",
    "        # ÂÖà‰∏çËÄÉËôëpaddingÊ†áÁ≠æÁöÑÈóÆÈ¢ò\n",
    "        # ÂÖà‰∏çËÄÉËôëmaskÁöÑÈóÆÈ¢ò\n",
    "        self.trans = nn.Parameter(torch.Tensor(num_label, num_label))\n",
    "        nn.init.kaiming_uniform_(self.trans, a=math.sqrt(5))\n",
    "        \n",
    "    def _path_score(self, inputs, labels):\n",
    "        return _path_score(inputs, labels, self.trans)\n",
    "        \n",
    "    def _sum_over_path_score(self, inputs, labels):\n",
    "        return _sum_over_path_score(inputs, labels, self.trans)\n",
    "    \n",
    "    def veterbi_decode(self, nodes):\n",
    "        return _veterbi_decode(nodes, self.trans.detached().numpy())\n",
    "    \n",
    "    def forward(self, inputs, labels):\n",
    "        \"\"\"\n",
    "        inputs: (batch_size, max_seq_len, label_num) embed with latent dim label_nun\n",
    "        labels: (batch_size, max_seq_len, label_num) ground-truth label in onehot\n",
    "        return: score\n",
    "       \"\"\"\n",
    "        path_score = self._path_score(inputs, labels)\n",
    "        sum_over_path = self._sum_over_path_score(inputs, labels)\n",
    "        \n",
    "        return torch.sum(- path_score + sum_over_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:48.294341Z",
     "start_time": "2020-03-22T10:13:48.282348Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# trans[i][j]Ë°®Á§∫‰ªéiÊ†áÁ≠æËΩ¨ÁßªËá≥jÊ†áÁ≠æ\n",
    "def _path_score(inputs, labels, trans):\n",
    "    \"\"\"\n",
    "    score of h(y[i]) ground-truch y[i] plus its g[y[i]][y[i+1]], inputs for h, trans for g\n",
    "    inputs.size() # batch_size, max_seq_len, num_label\n",
    "    trans.size() # num_label, num_label\n",
    "    labels.size() #batch_size, max_seq_len, num_label\n",
    "    \"\"\"\n",
    "    sum_h_score = inputs * labels # batch_size, max_seq_len, num_label\n",
    "    sum_h_score = sum_h_score.sum(-1, ) # batch_size, max_seq_len\n",
    "    sum_h_score = sum_h_score.sum(-1, keepdim = True) # batch_size, 1\n",
    "\n",
    "    mask = get_shift_mask(labels) # (batch_size, max_seq_len, num_label, num_label)\n",
    "    sum_g_score = mask * trans[None, None]\n",
    "    sum_g_score = sum_g_score.sum((-1, -2)) # batch_size, max_seq_len\n",
    "    sum_g_score = sum_g_score.sum((-1), keepdim = True) # batch_size, 1 \n",
    "    path_score = sum_g_score + sum_h_score\n",
    "    path_score.shape # batc_size, 1\n",
    "    return path_score\n",
    "\n",
    "def _sum_over_path_score(inputs, labels, trans):\n",
    "    \"\"\"\n",
    "    @see https://kexue.fm/archives/5542#%E5%BD%92%E4%B8%80%E5%8C%96%E5%9B%A0%E5%AD%90\n",
    "    \"\"\"\n",
    "    trans = trans[None, :, :] # (1, num_label, num_label,)\n",
    "    Z = inputs[:,0,:]\n",
    "    inputs = inputs[:, 1:,:]\n",
    "    times_seq_len = inputs.shape[1]\n",
    "    Z.shape\n",
    "    for time_idx in range(times_seq_len):\n",
    "            h = inputs[:, time_idx, :] # batch_size, num_label\n",
    "            Z = Z[:,:, None] # as row coeffiecient, (batch_size, num_label, 1)\n",
    "            Z = Z + trans\n",
    "            Z = torch.logsumexp(Z, -2)\n",
    "            Z = Z + h\n",
    "    Z = torch.logsumexp(Z, -1)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:48.331326Z",
     "start_time": "2020-03-22T10:13:48.299338Z"
    }
   },
   "outputs": [],
   "source": [
    "#test_export\n",
    "import torch.functional as F\n",
    "# Á©∫‰πüÊîæËøõÂéªÊò†Â∞Ñ‰∫ÜÔºå‰∏çÁî®Âä†1ÔºåÂê¶ÂàôÂõûÂá∫Áé∞ÈöèÊú∫ÁöÑtag2id.reserveÔºåÈîÆÂÄº‰∏çÂ≠òÂú®ÈîôËØØ„ÄÇ\n",
    "num_embeddings = len(c2id)\n",
    "num_label = len(tag2id)\n",
    "embedding_dim = 64\n",
    "lstm_dim = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:48.351308Z",
     "start_time": "2020-03-22T10:13:48.337320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:48.631146Z",
     "start_time": "2020-03-22T10:13:48.356305Z"
    }
   },
   "outputs": [],
   "source": [
    "#test_export\n",
    "# ‰∏çËøácrfÁöÑÔºåÁî®‰∫§ÂèâÁÜµ\n",
    "class TestNER(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=lstm_dim)\n",
    "        self.fc = nn.Linear(lstm_dim, num_label)\n",
    "        self.crf = CRF(num_label)\n",
    "        self.nodes = None\n",
    "        \n",
    "    def decode(self):\n",
    "        self.crf.veterbi_decode(self.nodes.detach.numpy())\n",
    "        \n",
    "    def forward_nodes(self, inputs):\n",
    "        x = self.emb(inputs)\n",
    "        x, (hn, cn)= self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        self.nodes = x\n",
    "        return x\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs, labels):\n",
    "        x = self.forward_nodes(inputs)\n",
    "        x = self.crf(x, labels)\n",
    "        return x\n",
    "        \n",
    "lr = 1e-4\n",
    "testner = TestNER()\n",
    "for train in get_data():\n",
    "    break;\n",
    "del testner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:45:11.756047Z",
     "start_time": "2020-03-12T15:45:11.729276Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "train_X, train_Y = train\n",
    "train_Y = onehot(train_Y, num_label)\n",
    "train_Y = torch.Tensor(train_Y)\n",
    "train_X = torch.LongTensor(train_X)\n",
    "# differs for tensor and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:45:15.025260Z",
     "start_time": "2020-03-12T15:45:11.758633Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestNER(\n",
       "  (emb): Embedding(1794, 64)\n",
       "  (lstm): LSTM(64, 32)\n",
       "  (fc): Linear(in_features=32, out_features=30, bias=True)\n",
       "  (crf): CRF()\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# todo test cuda\n",
    "train_X = train_X.cuda()\n",
    "train_Y = train_Y.cuda()\n",
    "testner.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:45:16.989605Z",
     "start_time": "2020-03-12T15:45:15.027108Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "for ep in range(20):\n",
    "    testner.zero_grad()\n",
    "    outputs = testner(train_X, train_Y)\n",
    "#     print(outputs.shape, train_Y.shape)\n",
    "#     loss = nn.CrossEntropyLoss(outputs, train_Y)\n",
    "    loss = outputs.sum()\n",
    "    print(loss)\n",
    "#     print(loss)\n",
    "    loss.backward()\n",
    "    with torch.no_grad() :\n",
    "        for p in testner.parameters():\n",
    "            p.data.add_(-lr, p.grad.data)\n",
    "    \n",
    "#     testner??\n",
    "#     break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:45:17.245765Z",
     "start_time": "2020-03-12T15:45:16.992269Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "#test_export\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "class Parser:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def parse_one_seq(self,seq_nodes, trans = None):\n",
    "        if trans is None:\n",
    "            trans = self.model.crf.trans.detach().numpy()\n",
    "        pred=viterbi(seq_nodes, trans)\n",
    "        return pred\n",
    "    \n",
    "    def parse_nodes(self, nodes=None, trans=None):\n",
    "        if nodes is None:\n",
    "            nodes = self.model.nodes.detach().numpy()\n",
    "        if trans is None:\n",
    "            trans = self.model.crf.trans.detach().numpy()\n",
    "        \n",
    "        parse = partial(self.parse_one_seq, trans = trans)\n",
    "        self.y_pred = list(map(parse, nodes))\n",
    "        self.y_pred = np.array(self.y_pred)\n",
    "        return self.y_pred\n",
    "    \n",
    "    def parse_test(self, test_X, test_Y):\n",
    "        assert len(test_Y.shape) == 2, \"please give test_Y in shape (batch_size, max_seq_len) tag in sparse int, given\"+str(test_Y.shape)\n",
    "        with torch.no_grad():\n",
    "            nodes = self.model.forward_nodes(test_X)\n",
    "        y_pred = self.parse_nodes(nodes)\n",
    "        return self.cvt_report(test_Y, y_pred)\n",
    "    \n",
    "    def cvt_report(self, y_pred, y_true):\n",
    "        y_pred, y_true = map(self.cvt, (y_pred, y_true)) \n",
    "        print(list(map(np.shape, (y_pred, y_true ))))\n",
    "        print(list(map(np.dtype, (y_pred, y_true ))))\n",
    "        print((y_pred, y_true ))\n",
    "        return classification_report(y_true, y_pred)\n",
    "    \n",
    "    def cvt(self, y):\n",
    "        return list(map(tag2id.reveres_list, y))\n",
    "    \n",
    "parser = Parser(testner)\n",
    "y_pred = parser.parse_nodes()\n",
    "y_pred = parser.cvt(y_pred)\n",
    "y_true = parser.cvt(train[1])\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "assert isinstance(y_pred, list)\n",
    "len(y_pred).should.eql(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:45:17.247568Z",
     "start_time": "2020-03-12T15:45:08.630Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "#test_export\n",
    "del testner, train, train_X, train_Y,  y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:49.057179Z",
     "start_time": "2020-03-22T10:13:48.641142Z"
    }
   },
   "outputs": [],
   "source": [
    "print_gc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:49.080503Z",
     "start_time": "2020-03-22T10:13:49.057179Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# TODO move this to common if duplicates\n",
    "import tqdm as _tqdm\n",
    "def _simple_tqdm(g):\n",
    "    \"\"\"\n",
    "    for travis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        l = len(g)\n",
    "    except TypeError:\n",
    "        l = '?'\n",
    "    for i,x in enumerate(g):\n",
    "        print(f\"({i}/{l})\", end='')\n",
    "        yield x\n",
    "\n",
    "if common.IN_JUPYTER:\n",
    "    tqdm = _tqdm.notebook.tqdm\n",
    "elif common.IN_TRAVIS:\n",
    "    tqdm = _simple_tqdm\n",
    "else :\n",
    "    tqdm = _tqdm.tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:49.096126Z",
     "start_time": "2020-03-22T10:13:49.080503Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:49.353777Z",
     "start_time": "2020-03-22T10:13:49.096126Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0/10)0\n",
      "(1/10)1\n",
      "(2/10)2\n",
      "(3/10)3\n",
      "(4/10)4\n",
      "(5/10)5\n",
      "(6/10)6\n",
      "(7/10)7\n",
      "(8/10)8\n",
      "(9/10)9\n",
      "(0/1910)"
     ]
    }
   ],
   "source": [
    "#test_export\n",
    "it = _simple_tqdm(1)\n",
    "next.when.called_with(it).should.throw(TypeError)\n",
    "\n",
    "for i in _simple_tqdm(range(10)):\n",
    "    print(i)\n",
    "    pass\n",
    "for i in _simple_tqdm(get_data()):\n",
    "    a, b = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:49.360771Z",
     "start_time": "2020-03-22T10:13:49.356772Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:23:19.930489Z",
     "start_time": "2020-03-19T07:23:19.692217Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "test_ner = TestNER()\n",
    "test_ner.cuda()\n",
    "cnt = 0\n",
    "for train in tqdm(get_data(100)):\n",
    "    test_ner.zero_grad()\n",
    "\n",
    "    if common.IN_JUPYTER or common.IN_TRAVIS: \n",
    "        # avoid overtime\n",
    "#             if cnt > 10:\n",
    "#                 break\n",
    "        pass\n",
    "    cnt += 1\n",
    "\n",
    "    train_X, train_Y = train\n",
    "    train_Y = onehot(train_Y, num_label)\n",
    "    train_Y = torch.Tensor(train_Y)\n",
    "    train_X = torch.LongTensor(train_X)\n",
    "    train_X = train_X.cuda()\n",
    "    train_Y = train_Y.cuda()\n",
    "\n",
    "    outputs = test_ner(train_X, train_Y)\n",
    "#     print(outputs.shape, train_Y.shape)\n",
    "#     loss = nn.CrossEntropyLoss(outputs, train_Y)\n",
    "    loss = outputs.sum()\n",
    "    print(cnt, loss)\n",
    "    loss.backward()\n",
    "    with torch.no_grad() :\n",
    "        for p in test_ner.parameters():\n",
    "            p.data.add_(-lr, p.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:13:49.379759Z",
     "start_time": "2020-03-22T10:13:49.363769Z"
    }
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "strinfos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:14:13.819151Z",
     "start_time": "2020-03-22T10:13:49.381758Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c434349e58fc4a55adf74dfa7c75902f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72330ded53f84c0aac2f862175424da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=382.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32125.3770, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe9fbdd814240aeb4cbd8f6734ca4c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=382.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(30366.3906, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f323167024940d2935b7b2465d5cbc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=382.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(28842.6855, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741df96d42954126833a1630c17c6e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=382.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(27385.2598, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64cbeaaf8fb4a4eac9fcff59e3e3867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=382.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(25936.3867, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02170b6eaeeb4306aaab0f4c1f916119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=382.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24484.1426, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e65dd42e29b4d079a540b613f7eb276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=382.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(23038.5059, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547d2507e2604cce8a3f6eb183454572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=382.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(21623.8242, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a9dde34ee04a0f8566800be8ac7a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=382.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20275.1680, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb75203b755848729a204438bf043813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=382.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19032.9453, grad_fn=<SumBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test_export\n",
    "test_ner = TestNER()\n",
    "if is_cuda():\n",
    "    test_ner.cuda()\n",
    "def train_ep():\n",
    "    cnt = 0\n",
    "    for train in tqdm(get_data(10)):\n",
    "        test_ner.zero_grad()\n",
    "        \n",
    "        if common.IN_JUPYTER or common.IN_TRAVIS: \n",
    "            if not is_cuda():\n",
    "                if cnt > 5:\n",
    "                    break\n",
    "            pass\n",
    "        cnt += 1\n",
    "        \n",
    "        train_X, train_Y = train\n",
    "        train_Y = onehot(train_Y, num_label)\n",
    "        train_Y = torch.Tensor(train_Y)\n",
    "        train_X = torch.LongTensor(train_X)\n",
    "        if is_cuda():\n",
    "            train_X = train_X.cuda()\n",
    "            train_Y = train_Y.cuda()\n",
    "\n",
    "        outputs = test_ner(train_X, train_Y)\n",
    "    #     print(outputs.shape, train_Y.shape)\n",
    "    #     loss = nn.CrossEntropyLoss(outputs, train_Y)\n",
    "        loss = outputs.sum()\n",
    "        loss.backward()\n",
    "        with torch.no_grad() :\n",
    "            for p in test_ner.parameters():\n",
    "                p.data.add_(-lr, p.grad.data)\n",
    "        strinfos.append(StringIO(f\"{cnt}\"))\n",
    "        print_gc(strinfos[-1])\n",
    "        gc.collect()\n",
    "#         break\n",
    "    return loss\n",
    "for ep in tqdm(range(10)):\n",
    "    print(train_ep())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:14:13.826148Z",
     "start_time": "2020-03-22T10:14:13.822150Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(strinfos[169].getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:14:13.849138Z",
     "start_time": "2020-03-22T10:14:13.831145Z"
    }
   },
   "outputs": [],
   "source": [
    "# print_gc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:14:15.332844Z",
     "start_time": "2020-03-22T10:14:13.853132Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted CRF.ipynb to ..\\exp\\CRF.py\n",
      "Converted CRF.ipynb to ..\\test\\test_CRF.py\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "common.save_and_export_notebook('CRF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:24:59.305796Z",
     "start_time": "2020-03-19T07:24:59.295763Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3torch-cpu",
   "language": "python",
   "name": "py3torch-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
