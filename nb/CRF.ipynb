{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:05:58.541180Z",
     "start_time": "2020-03-12T15:05:58.517228Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import sys\n",
    "if __name__ == '__main__': sys.path.append('..')\n",
    "import exp.common as common\n",
    "from pprint import pprint\n",
    "def pj(*args, **kargs):\n",
    "    if common.IN_JUPYTER:\n",
    "        pprint(*args, **kargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:05:58.548064Z",
     "start_time": "2020-03-12T15:05:58.544162Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# Ê®°ÂûãÂèÇËÄÉhttps://github.com/bojone/crf/\n",
    "# CRFÂÆûÁé∞ÂèÇËÄÉhttps://github.com/bojone/crf/blob/master/crf_keras.py#L54\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### READ Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:05:59.657463Z",
     "start_time": "2020-03-12T15:05:58.552366Z"
    }
   },
   "outputs": [],
   "source": [
    "#test_export\n",
    "import pandas as pd\n",
    "def read_data(Forever=False):\n",
    "    sent, tags = [],[]\n",
    "    con = True\n",
    "    while con:\n",
    "        with open('../data/CRF/ResumeNER/train.char.bmes', 'r', encoding='UTF-8') as f:\n",
    "            for line in f.readlines():\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    yield sent, tags\n",
    "                    sent, tags = [],[]\n",
    "                    continue\n",
    "\n",
    "                assert len(line.split())>=2, line\n",
    "                w, tag = line.split()\n",
    "                sent.append(w)\n",
    "                tags.append(tag)\n",
    "        con = Forever\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "# next(read_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:05:59.670150Z",
     "start_time": "2020-03-12T15:05:59.659324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {1:3}\n",
    "# d.items()\n",
    "dict(map(reversed, d.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:05:59.952882Z",
     "start_time": "2020-03-12T15:05:59.671723Z"
    }
   },
   "outputs": [],
   "source": [
    "#test_export\n",
    "import sure\n",
    "from collections import Counter\n",
    "\n",
    "# ÂáÜÂ§áÊï∞ÊçÆ\n",
    "# Counter return 0 for unknow key\n",
    "class C2ID(Counter):\n",
    "    \n",
    "    # 0 for unknow\n",
    "    def __init__(self):\n",
    "        super().__init__(self)\n",
    "        self.min_freq = 1\n",
    "        # 0 for unknow\n",
    "        self.indexer = 0\n",
    "        self.freq_cnt = Counter()\n",
    "        self._reverse_dict = {}\n",
    "    \n",
    "    def touchc(self, c):\n",
    "        self.freq_cnt[c] += 1\n",
    "        \n",
    "    def touchs(self, s):\n",
    "        for c in s:\n",
    "            self.touchc(c)\n",
    "    \n",
    "    def update_index(self):\n",
    "        for k,v in self.freq_cnt.items():\n",
    "            if v < self.min_freq: continue\n",
    "            if k in self: continue\n",
    "                \n",
    "            self._reverse_dict[self.indexer]=k\n",
    "            self[k] = self.indexer\n",
    "            \n",
    "            self.indexer += 1\n",
    "    \n",
    "    def reverse(self, idx):\n",
    "        return self._reverse_dict[idx]\n",
    "    \n",
    "    def reveres_list(self, list_idx):\n",
    "        return list(map(self.reverse, list_idx))\n",
    "            \n",
    "c2id = C2ID()\n",
    "tag2id = C2ID()\n",
    "# tag2id.indexer = 0\n",
    "UNK = 'UNK'\n",
    "PAD = 'PAD'\n",
    "for cv in [c2id, tag2id]:\n",
    "    cv.touchs([UNK, PAD])\n",
    "\n",
    "for sent, tags in read_data():\n",
    "    c2id.touchs(sent)\n",
    "    tag2id.touchs(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:05:59.959121Z",
     "start_time": "2020-03-12T15:05:59.954707Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1794"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c2id.freq_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:00.214029Z",
     "start_time": "2020-03-12T15:05:59.961080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mxlen 178 65671\n"
     ]
    }
   ],
   "source": [
    "#test_export\n",
    "# token ÁöÑÂàÜÂ∏É\n",
    "\n",
    "def is_breaker(c,t):\n",
    "    if c2id[c] == 0:\n",
    "        if t[0] == 'B':return True\n",
    "        if t[0] == 'M':return True\n",
    "        if t[0] == 'S':return True\n",
    "    return False\n",
    "\n",
    "def check_breaker():\n",
    "    max_len = 0\n",
    "    breaker_c = []\n",
    "    for sent, tags in read_data():\n",
    "        max_len = max(len(sent), max_len)\n",
    "        for c, t in zip(sent, tags):\n",
    "            if is_breaker(c, t): breaker_c.append(c)\n",
    "    return max_len, breaker_c\n",
    "\n",
    "# sorted(c2id.freq_cnt.items(), key=operator.itemgetter(1))[:30]\n",
    "df = pd.DataFrame(c2id.freq_cnt.items())\n",
    "mxlen, breaker_c = check_breaker()\n",
    "\n",
    "# ÂÖà‰∏çËÄÉËôëÂéªÈô§‰ΩéÈ¢ëÈ°π\n",
    "c2id.update_index() # 0 for padding\n",
    "tag2id.update_index() # 0 for unknown char\n",
    "print('mxlen', mxlen, len(breaker_c))\n",
    "import pandas  as pd\n",
    "# df = df.sort_values(by=1)\n",
    "\n",
    "# df.describe()\n",
    "# c2id.min_freq = 2\n",
    "# c2id.update_index()\n",
    "# Ê£ÄÊü•ÊúâÊ≤°ÊúâÊâìÊñ≠Ê†áÁ≠æ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:00.258981Z",
     "start_time": "2020-03-12T15:06:00.218145Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1794.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>69.175585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>280.915003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5141.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1\n",
       "count  1794.000000\n",
       "mean     69.175585\n",
       "std     280.915003\n",
       "min       1.000000\n",
       "25%       2.000000\n",
       "50%       6.000000\n",
       "75%      23.000000\n",
       "max    5141.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_export\n",
    "# token ÁöÑÂàÜÂ∏É\n",
    "import pandas  as pd\n",
    "sorted(c2id.freq_cnt.items(), key=operator.itemgetter(1))[:30]\n",
    "df = pd.DataFrame(c2id.freq_cnt.items())\n",
    "df = df.sort_values(by=1)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:00.276565Z",
     "start_time": "2020-03-12T15:06:00.262512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAD', 'B-NAME', 'E-NAME']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_export\n",
    "# tag ÁöÑÂàÜÂ∏É\n",
    "import pandas  as pd\n",
    "sorted(tag2id.freq_cnt.items(), key=operator.itemgetter(1))[:30]\n",
    "df = pd.DataFrame(tag2id.freq_cnt.items())\n",
    "# df = df.sort_values(by=1)\n",
    "# df.describe()\n",
    "df[ list(map(lambda x:x[0] == 'B' or x[0] == 'S', df[0]) )][1].sum()\n",
    "# df\n",
    "tag2id.reveres_list([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T03:30:43.154605Z",
     "start_time": "2020-03-11T03:30:43.150611Z"
    }
   },
   "source": [
    "#### onehot and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:00.283464Z",
     "start_time": "2020-03-12T15:06:00.278683Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def padding(padding_idx,X):\n",
    "    X = list(X)\n",
    "    max_len = max(map(len, X))\n",
    "    for i,x in enumerate(X):\n",
    "        X[i] = x + [padding_idx] * (max_len - len(x))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:00.291737Z",
     "start_time": "2020-03-12T15:06:00.287433Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from torch import nn\n",
    "def onehot(y, dim_size):\n",
    "    \"\"\"\n",
    "    y: shape (batch_size, max_seq_len)\n",
    "    \"\"\"\n",
    "    assert len(y.shape) == 2, y.shape\n",
    "    eye = np.eye(dim_size)\n",
    "    return eye[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:00.529359Z",
     "start_time": "2020-03-12T15:06:00.294264Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1911 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 68), (2, 68)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 2,  3,  4,  5,  6,  7,  8,  8,  9,  6, 10, 11, 12, 13, 14, 15,\n",
       "          6,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1],\n",
       "        [16, 17, 18, 18, 19, 20, 21,  6, 22, 23,  6,  7, 24, 25, 26,  6,\n",
       "         27, 28, 29, 30,  6, 31, 32, 33, 34, 35,  8, 36, 37, 38, 39, 40,\n",
       "         41, 42, 43, 41, 26, 44, 45, 46, 47, 46, 48, 49, 50, 48, 51, 52,\n",
       "         34, 42, 43, 36, 37, 38, 39, 53, 54, 44, 45, 46, 45, 52, 34, 36,\n",
       "         37, 55, 39, 56]]),\n",
       " array([[ 2,  3,  4,  4,  4,  5,  6,  6,  7,  4,  4,  4,  4,  4,  4,  4,\n",
       "          4,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1],\n",
       "        [ 4,  4,  4,  4,  4,  4,  4,  4,  8,  9,  4, 10, 11, 11, 12,  4,\n",
       "         13, 14, 14, 15,  4, 10, 11, 12,  4, 16, 17, 17, 17, 17, 17, 17,\n",
       "         18, 10, 11, 11, 12,  4, 10, 11, 11, 11, 11, 11, 11, 11, 12,  4,\n",
       "          4, 10, 11, 11, 11, 11, 11, 11, 12,  4, 10, 11, 12,  4,  4, 10,\n",
       "         11, 11, 12,  4]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_export\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "assert isinstance( math.ceil(0.3), int)\n",
    "\n",
    "class get_data():\n",
    "    def __init__(self, batch_size = 2):\n",
    "        self.batch_size = batch_size\n",
    "        self.len = math.ceil( len(list(read_data()))/batch_size )\n",
    "        \n",
    "    def __iter__(self):\n",
    "        batch_size = self.batch_size\n",
    "        cnt = 0\n",
    "        X = []\n",
    "        Y = []\n",
    "        def set_train():\n",
    "            a = padding(c2id[PAD]  , X)\n",
    "            b = padding(tag2id[PAD], Y)\n",
    "            return tuple(map( np.array, (a,b)))\n",
    "        for x, y in read_data():\n",
    "            cnt += 1\n",
    "            X.append(list(map(  c2id.__getitem__, x)))\n",
    "            Y.append(list(map(tag2id.__getitem__, y)))\n",
    "    \n",
    "            if cnt == batch_size:\n",
    "                cnt = 0\n",
    "                yield set_train()\n",
    "        \n",
    "        return set_train()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "for x in tqdm(get_data()):\n",
    "    break\n",
    "print(list(map(np.shape, x)))\n",
    "x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:00.537352Z",
     "start_time": "2020-03-12T15:06:00.530893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]],\n",
       "\n",
       "       [[1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_export\n",
    "onehot(np.array(\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [0,3,1]\n",
    "    ]\n",
    "), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### TopK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:00.572647Z",
     "start_time": "2020-03-12T15:06:00.541917Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "import sure\n",
    "from queue import PriorityQueue\n",
    "class TopK:\n",
    "    def __init__(self, k, topks = None):\n",
    "        # (priority_number, data)\n",
    "#         pq = PriorityQueue(k)\n",
    "        assert k == 1, \"not implemented\"\n",
    "    \n",
    "        self.m_inf = -float('inf')\n",
    "        self.data = None\n",
    "        self.score = self.m_inf\n",
    "        \n",
    "        if topks is not None:\n",
    "            assert len(topks) >= k\n",
    "            for t in topks:\n",
    "                self.put( t.get_max_data(), t.get_max_score(),)\n",
    "            return \n",
    "    \n",
    "#         for i in range(k):\n",
    "#             pq.put_nowait((m_inf))\n",
    "#         self.pq = pq\n",
    "        \n",
    "    def put(self,  data, score,):\n",
    "        assert len(data) >= 1\n",
    "        if self.score is self.m_inf:\n",
    "            pass\n",
    "        else :\n",
    "            assert type(score) == type(self.score), \"score type muse consit\"\n",
    "        if score > self.score:\n",
    "            self.score, self.data = score, data\n",
    "    \n",
    "    def __str__(self):\n",
    "        return (self.score, self.data).__str__()\n",
    "    \n",
    "    def get_max_score(self):\n",
    "        return self.score\n",
    "    \n",
    "    def get_max_data(self):\n",
    "        return self.data\n",
    "    \n",
    "    def get_kth_data(self, k):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def get_kth_score(self, k):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "        \n",
    "    \n",
    "    \n",
    "topk = TopK(1)\n",
    "for i in range(10):\n",
    "    topk.put( [i],i+10,)\n",
    "#     print(topk.data)\n",
    "# assert topk.\n",
    "topk.get_max_data().should.eql([9])\n",
    "topk.get_max_score().should.eql(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:00.582660Z",
     "start_time": "2020-03-12T15:06:00.575125Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_export\n",
    "topk = TopK(1)\n",
    "topk.put( [1], 1,)\n",
    "for i in range(1, 10):\n",
    "    t = list(range(i)) + topk.get_max_data()\n",
    "    topk.put(t, i)\n",
    "topk.m_inf.should.eql(topk.m_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:00.597212Z",
     "start_time": "2020-03-12T15:06:00.584449Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def viterbi(nodes,trans_p, initial_state = None, topk = 1, start_p = None):\n",
    "    \"\"\"\n",
    "    nodes: array, [{\"<TAG>\": <float>}]\n",
    "    trans_p: dict, {\"<TAG_A>\": {\"TAG_B\": <float>}}, TAG_A -> TAG-B\n",
    "    return_max=True: bool, set to False if your want to avoid ill endding tag and find your own.\n",
    "    initial_state=None: None or list to avoid impossible starting tags\n",
    "    start_p: P(o1), may be nessary\n",
    "    all float number in log form\n",
    "    \"\"\"\n",
    "    assert len(nodes.shape) == 2,len(nodes.shape)  # max_seq_len, label_num\n",
    "    kth = 1\n",
    "    if initial_state is None:\n",
    "        initial_state = nodes[0]\n",
    "        nodes = nodes[1:]\n",
    "        \n",
    "    def init_tok():return TopK(kth)\n",
    "    \n",
    "    def init_toks(): return [init_tok() for i in range(nodes.shape[-1])]\n",
    "\n",
    "    last_best_nodes = init_toks()\n",
    "    next_best_nodes = init_toks()\n",
    "    \n",
    "    \n",
    "    for idx, (tk,score) in enumerate( zip(last_best_nodes , initial_state)):\n",
    "        tk.put([idx], score)\n",
    "\n",
    "    for node in nodes:\n",
    "        for t,v in enumerate(node):\n",
    "\n",
    "            current_best_node = init_tok() # for t\n",
    "            \n",
    "            for topk in last_best_nodes:\n",
    "                path = topk.get_max_data()\n",
    "                score = topk.get_max_score()\n",
    "                \n",
    "                last_t = path[-1]\n",
    "                new_path = path + [t]\n",
    "                tran = trans_p[last_t][t]\n",
    "                \n",
    "                current_best_node.put(new_path, score + tran + v)\n",
    "\n",
    "            next_best_nodes[t] = current_best_node\n",
    "            \n",
    "        next_best_nodes, last_best_nodes =  last_best_nodes, next_best_nodes,\n",
    "        \n",
    "    topk = TopK(1, last_best_nodes)\n",
    "    \n",
    "    return topk.get_max_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:00.606786Z",
     "start_time": "2020-03-12T15:06:00.599078Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_export\n",
    "nodes = [\n",
    "    [1, 2, 1],\n",
    "    [1, 1, 3],\n",
    "    [4, 1, 3],\n",
    "]\n",
    "trans = [\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1],\n",
    "]\n",
    "nodes, trans = map(np.array, [nodes, trans])\n",
    "viterbi(nodes, trans).should.eql([1,2,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### get_shift_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:00.613160Z",
     "start_time": "2020-03-12T15:06:00.608634Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_shift_mask(labels):\n",
    "    \"\"\"\n",
    "    labels: (batch_size, max_seq_len, num_label) in onehot all element should be 1/0\n",
    "    turn num_labels into matrix of (num_label, num_label) where m[ y[i] ][ y[i+1] ] = 1, 0 for else\n",
    "    return (batch_size, max_seq_len, num_label, num_label)\n",
    "    \"\"\"\n",
    "    labels1 = labels[:, :-1, ] # y[i]\n",
    "\n",
    "    labels2 = labels[:, 1:] # y[i + 1]\n",
    "\n",
    "    labels1 = labels1[:, :, :, None] # as Á≥ªÊï∞, row indexer\n",
    "    labels2 = labels2[:, :, None, :] # as row, col indexer\n",
    "\n",
    "    shift_mask = labels1 * labels2\n",
    "    return shift_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:00.621558Z",
     "start_time": "2020-03-12T15:06:00.614856Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#test_export\n",
    "import sure\n",
    "tmp_num_label = 5\n",
    "tmp_labels_raw = [[1,2,3,4], [3,3,3,2]]\n",
    "tmp_labels = np.array(tmp_labels_raw)\n",
    "tmp_labels = onehot(tmp_labels, tmp_num_label)\n",
    "shift_mask = get_shift_mask(tmp_labels)\n",
    "\n",
    "# for batch\n",
    "for tags, mask in zip(tmp_labels_raw, shift_mask):\n",
    "    \n",
    "    # for seq\n",
    "    # len = max_seq_len - 1\n",
    "    for y_i, y_j,matrix in zip(tags[:-1], tags[1:], mask):\n",
    "        # y_j  = y[i+1]\n",
    "        matrix = np.copy(matrix)\n",
    "        matrix[y_i][y_j] -= 1 # only matrix[y_i][y_j] = 1, else 0\n",
    "        matrix.sum().should.eql(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:00.632975Z",
     "start_time": "2020-03-12T15:06:00.623080Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import math\n",
    "# üë¥ÁöÑCRF\n",
    "class CRF(nn.Module):\n",
    "    def __init__(self, num_label):\n",
    "        super().__init__()\n",
    "        # ÂÖà‰∏çËÄÉËôëpaddingÊ†áÁ≠æÁöÑÈóÆÈ¢ò\n",
    "        # ÂÖà‰∏çËÄÉËôëmaskÁöÑÈóÆÈ¢ò\n",
    "        self.trans = nn.Parameter(torch.Tensor(num_label, num_label))\n",
    "        nn.init.kaiming_uniform_(self.trans, a=math.sqrt(5))\n",
    "        \n",
    "    def _path_score(self, inputs, labels):\n",
    "        return _path_score(inputs, labels, self.trans)\n",
    "        \n",
    "    def _sum_over_path_score(self, inputs, labels):\n",
    "        return _sum_over_path_score(inputs, labels, self.trans)\n",
    "    \n",
    "    def veterbi_decode(self, nodes):\n",
    "        return _veterbi_decode(nodes, self.trans.detached().numpy())\n",
    "    \n",
    "    def forward(self, inputs, labels):\n",
    "        \"\"\"\n",
    "        inputs: (batch_size, max_seq_len, label_num) embed with latent dim label_nun\n",
    "        labels: (batch_size, max_seq_len, label_num) ground-truth label in onehot\n",
    "        return: score\n",
    "       \"\"\"\n",
    "        path_score = self._path_score(inputs, labels)\n",
    "        sum_over_path = self._sum_over_path_score(inputs, labels)\n",
    "        \n",
    "        return - path_score + sum_over_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:00.646211Z",
     "start_time": "2020-03-12T15:06:00.634699Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# trans[i][j]Ë°®Á§∫‰ªéiÊ†áÁ≠æËΩ¨ÁßªËá≥jÊ†áÁ≠æ\n",
    "def _path_score(inputs, labels, trans):\n",
    "    \"\"\"\n",
    "    score of h(y[i]) ground-truch y[i] plus its g[y[i]][y[i+1]], inputs for h, trans for g\n",
    "    inputs.size() # batch_size, max_seq_len, num_label\n",
    "    trans.size() # num_label, num_label\n",
    "    labels.size() #batch_size, max_seq_len, num_label\n",
    "    \"\"\"\n",
    "    sum_h_score = inputs * labels # batch_size, max_seq_len, num_label\n",
    "    sum_h_score = sum_h_score.sum(-1, ) # batch_size, max_seq_len\n",
    "    sum_h_score = sum_h_score.sum(-1, keepdim = True) # batch_size, 1\n",
    "\n",
    "    mask = get_shift_mask(labels)\n",
    "    sum_g_score = mask * trans[None, None]\n",
    "    sum_g_score = sum_g_score.sum((-1, -2)) # batch_size, max_seq_len\n",
    "    sum_g_score = sum_g_score.sum((-1), keepdim = True) # batch_size, 1 \n",
    "    path_score = sum_g_score + sum_h_score\n",
    "    path_score.shape # batc_size, 1\n",
    "    return path_score\n",
    "\n",
    "def _sum_over_path_score(inputs, labels, trans):\n",
    "    \"\"\"\n",
    "    @see https://kexue.fm/archives/5542#%E5%BD%92%E4%B8%80%E5%8C%96%E5%9B%A0%E5%AD%90\n",
    "    \"\"\"\n",
    "    trans = trans[None, :, :]\n",
    "    Z = inputs[:,0,:]\n",
    "    inputs = inputs[:, 1:,:]\n",
    "    times_seq_len = inputs.shape[1]\n",
    "    Z.shape\n",
    "    for time_idx in range(times_seq_len):\n",
    "            h = inputs[:, time_idx, :]\n",
    "            Z = Z[:,:, None] # as row coeffiecient\n",
    "            Z = Z + trans\n",
    "            Z = torch.logsumexp(Z, -2)\n",
    "            Z = Z + h\n",
    "    Z = Z.sum(-1)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:00.651518Z",
     "start_time": "2020-03-12T15:06:00.648103Z"
    }
   },
   "outputs": [],
   "source": [
    "#test_export\n",
    "import torch.functional as F\n",
    "# Á©∫‰πüÊîæËøõÂéªÊò†Â∞Ñ‰∫ÜÔºå‰∏çÁî®Âä†1ÔºåÂê¶ÂàôÂõûÂá∫Áé∞ÈöèÊú∫ÁöÑtag2id.reserveÔºåÈîÆÂÄº‰∏çÂ≠òÂú®ÈîôËØØ„ÄÇ\n",
    "num_embeddings = len(c2id)\n",
    "num_label = len(tag2id)\n",
    "embedding_dim = 64\n",
    "lstm_dim = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:00.668117Z",
     "start_time": "2020-03-12T15:06:00.655545Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:00.870951Z",
     "start_time": "2020-03-12T15:06:00.670184Z"
    }
   },
   "outputs": [],
   "source": [
    "#test_export\n",
    "# ‰∏çËøácrfÁöÑÔºåÁî®‰∫§ÂèâÁÜµ\n",
    "class TestNER(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=lstm_dim)\n",
    "        self.fc = nn.Linear(lstm_dim, num_label)\n",
    "        self.crf = CRF(num_label)\n",
    "        self.nodes = None\n",
    "        \n",
    "    def decode(self):\n",
    "        self.crf.veterbi_decode(self.nodes.detach.numpy())\n",
    "        \n",
    "    def forward_nodes(self, inputs):\n",
    "        x = self.emb(inputs)\n",
    "        x, (hn, cn)= self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        self.nodes = x\n",
    "        return x\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs, labels):\n",
    "        x = self.forward_nodes(inputs)\n",
    "        x = self.crf(x, labels)\n",
    "        return x\n",
    "        \n",
    "lr = 1e-4\n",
    "testner = TestNER()\n",
    "for train in get_data():\n",
    "    break;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:00.874810Z",
     "start_time": "2020-03-12T15:06:00.872765Z"
    }
   },
   "outputs": [],
   "source": [
    "#ÊµãËØïgpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:01.486459Z",
     "start_time": "2020-03-12T15:06:00.876304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 12 23:06:01 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 430.26       Driver Version: 430.26       CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  P106-100            Off  | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 34%   34C    P0    26W / 120W |      0MiB /  6080MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  P106-100            Off  | 00000000:03:00.0 Off |                  N/A |\r\n",
      "|  0%   26C    P8     4W / 120W |     10MiB /  6080MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  P106-100            Off  | 00000000:84:00.0 Off |                  N/A |\r\n",
      "| 31%   29C    P8     5W / 120W |   5823MiB /  6080MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    2      5986      C   tensorflow_model_server                     5809MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "# TODO move this to common\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:01.516632Z",
     "start_time": "2020-03-12T15:06:01.489574Z"
    }
   },
   "outputs": [],
   "source": [
    "train_X, train_Y = train\n",
    "train_Y = onehot(train_Y, num_label)\n",
    "train_Y = torch.Tensor(train_Y)\n",
    "train_X = torch.LongTensor(train_X)\n",
    "# differs for tensor and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:01.522575Z",
     "start_time": "2020-03-12T15:06:01.519445Z"
    }
   },
   "outputs": [],
   "source": [
    "# todo test cuda\n",
    "# train_X = train_X.cuda()\n",
    "# train_Y = train_Y.cuda()\n",
    "# testner.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:02.741006Z",
     "start_time": "2020-03-12T15:06:01.525810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(27486.5645, grad_fn=<SumBackward0>)\n",
      "tensor(27135.6094, grad_fn=<SumBackward0>)\n",
      "tensor(26800.7246, grad_fn=<SumBackward0>)\n",
      "tensor(26463.0957, grad_fn=<SumBackward0>)\n",
      "tensor(26114.4512, grad_fn=<SumBackward0>)\n",
      "tensor(25749.0801, grad_fn=<SumBackward0>)\n",
      "tensor(25362.0605, grad_fn=<SumBackward0>)\n",
      "tensor(24948.9531, grad_fn=<SumBackward0>)\n",
      "tensor(24505.5371, grad_fn=<SumBackward0>)\n",
      "tensor(24027.6836, grad_fn=<SumBackward0>)\n",
      "tensor(23511.1641, grad_fn=<SumBackward0>)\n",
      "tensor(22951.5000, grad_fn=<SumBackward0>)\n",
      "tensor(22343.9746, grad_fn=<SumBackward0>)\n",
      "tensor(21683.9355, grad_fn=<SumBackward0>)\n",
      "tensor(20967.0957, grad_fn=<SumBackward0>)\n",
      "tensor(20189.4688, grad_fn=<SumBackward0>)\n",
      "tensor(19346.7285, grad_fn=<SumBackward0>)\n",
      "tensor(18433.6367, grad_fn=<SumBackward0>)\n",
      "tensor(17443.8301, grad_fn=<SumBackward0>)\n",
      "tensor(16369.6641, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for ep in range(20):\n",
    "    testner.zero_grad()\n",
    "    outputs = testner(train_X, train_Y)\n",
    "#     print(outputs.shape, train_Y.shape)\n",
    "#     loss = nn.CrossEntropyLoss(outputs, train_Y)\n",
    "    loss = outputs.sum()\n",
    "    print(loss)\n",
    "#     print(loss)\n",
    "    loss.backward()\n",
    "    with torch.no_grad() :\n",
    "        for p in testner.parameters():\n",
    "            p.data.add_(-lr, p.grad.data)\n",
    "    \n",
    "#     testner??\n",
    "#     break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:03.145963Z",
     "start_time": "2020-03-12T15:06:02.748389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "     CONT       0.00      0.00      0.00         1\n",
      "     RACE       0.00      0.00      0.00         1\n",
      "    TITLE       0.00      0.00      0.00         7\n",
      "      EDU       0.00      0.00      0.00         1\n",
      "      ORG       0.00      0.00      0.00         1\n",
      "     NAME       0.00      0.00      0.00         1\n",
      "      PAD       0.00      0.00      0.00         1\n",
      "\n",
      "micro avg       0.00      0.00      0.00        13\n",
      "macro avg       0.00      0.00      0.00        13\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_export\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "class Parser:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def parse_one_seq(self,seq_nodes, trans = None):\n",
    "        if trans is None:\n",
    "            trans = self.model.crf.trans.detach().numpy()\n",
    "        pred=viterbi(seq_nodes, trans)\n",
    "        return pred\n",
    "    \n",
    "    def parse_nodes(self, nodes=None, trans=None):\n",
    "        if nodes is None:\n",
    "            nodes = self.model.nodes.detach().numpy()\n",
    "        if trans is None:\n",
    "            trans = self.model.crf.trans.detach().numpy()\n",
    "        \n",
    "        parse = partial(self.parse_one_seq, trans = trans)\n",
    "        self.y_pred = list(map(parse, nodes))\n",
    "        self.y_pred = np.array(self.y_pred)\n",
    "        return self.y_pred\n",
    "    \n",
    "    def parse_test(self, test_X, test_Y):\n",
    "        assert len(test_Y.shape) == 2, \"please give test_Y in shape (batch_size, max_seq_len) tag in sparse int, given\"+str(test_Y.shape)\n",
    "        with torch.no_grad():\n",
    "            nodes = self.model.forward_nodes(test_X)\n",
    "        y_pred = self.parse_nodes(nodes)\n",
    "        return self.cvt_report(test_Y, y_pred)\n",
    "    \n",
    "    def cvt_report(self, y_pred, y_true):\n",
    "        y_pred, y_true = map(self.cvt, (y_pred, y_true)) \n",
    "        print(list(map(np.shape, (y_pred, y_true ))))\n",
    "        print(list(map(np.dtype, (y_pred, y_true ))))\n",
    "        print((y_pred, y_true ))\n",
    "        return classification_report(y_true, y_pred)\n",
    "    \n",
    "    def cvt(self, y):\n",
    "        return list(map(tag2id.reveres_list, y))\n",
    "    \n",
    "parser = Parser(testner)\n",
    "y_pred = parser.parse_nodes()\n",
    "y_pred = parser.cvt(y_pred)\n",
    "y_true = parser.cvt(train[1])\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "assert isinstance(y_pred, list)\n",
    "len(y_pred).should.eql(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:03.150230Z",
     "start_time": "2020-03-12T15:06:03.147642Z"
    }
   },
   "outputs": [],
   "source": [
    "#test_export\n",
    "del testner, train, train_X, train_Y,  y_pred, y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:03.211377Z",
     "start_time": "2020-03-12T15:06:03.151852Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# TODO move this to common if duplicates\n",
    "import tqdm as _tqdm\n",
    "def _simple_tqdm(g):\n",
    "    \"\"\"\n",
    "    for travis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        l = len(g)\n",
    "    except TypeError:\n",
    "        l = '?'\n",
    "    for i,x in enumerate(g):\n",
    "        print(f\"({i}/{l})\", end='')\n",
    "        yield x\n",
    "\n",
    "if common.IN_JUPYTER:\n",
    "    tqdm = _tqdm.notebook.tqdm\n",
    "elif common.IN_TRAVIS:\n",
    "    tqdm = _simple_tqdm\n",
    "else :\n",
    "    tqdm = _tqdm.tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:03.226001Z",
     "start_time": "2020-03-12T15:06:03.217788Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:06:04.671752Z",
     "start_time": "2020-03-12T15:06:04.295601Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0/10)0\n",
      "(1/10)1\n",
      "(2/10)2\n",
      "(3/10)3\n",
      "(4/10)4\n",
      "(5/10)5\n",
      "(6/10)6\n",
      "(7/10)7\n",
      "(8/10)8\n",
      "(9/10)9\n",
      "(0/1911)"
     ]
    }
   ],
   "source": [
    "#test_export\n",
    "it = _simple_tqdm(1)\n",
    "next.when.called_with(it).should.throw(TypeError)\n",
    "\n",
    "for i in _simple_tqdm(range(10)):\n",
    "    print(i)\n",
    "    pass\n",
    "for i in _simple_tqdm(get_data()):\n",
    "    a, b = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:16:27.093032Z",
     "start_time": "2020-03-12T15:16:27.086841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestNER(\n",
       "  (emb): Embedding(1794, 64)\n",
       "  (lstm): LSTM(64, 32)\n",
       "  (fc): Linear(in_features=32, out_features=30, bias=True)\n",
       "  (crf): CRF()\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:12:30.735239Z",
     "start_time": "2020-03-12T15:10:18.922320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b47155928049bd9bf9a16f03b7d3af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147c206683394694816c568927dd8391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=383.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.40 GiB (GPU 0; 5.94 GiB total capacity; 1.92 GiB already allocated; 1.40 GiB free; 4.10 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-bc14943ae2a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-bc14943ae2a2>\u001b[0m in \u001b[0;36mtrain_ep\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtrain_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_ner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;31m#     print(outputs.shape, train_Y.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#     loss = nn.CrossEntropyLoss(outputs, train_Y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-b27eeaa8bfa2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, labels)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-b537fae9b6f2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, labels)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m        \"\"\"\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpath_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0msum_over_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sum_over_path_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-b537fae9b6f2>\u001b[0m in \u001b[0;36m_path_score\u001b[0;34m(self, inputs, labels)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_path_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_path_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sum_over_path_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-af03fb407ffd>\u001b[0m in \u001b[0;36m_path_score\u001b[0;34m(inputs, labels, trans)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_shift_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0msum_g_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0msum_g_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_g_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch_size, max_seq_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0msum_g_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_g_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch_size, 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.40 GiB (GPU 0; 5.94 GiB total capacity; 1.92 GiB already allocated; 1.40 GiB free; 4.10 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "#test_export\n",
    "test_ner = TestNER()\n",
    "test_ner.cuda()\n",
    "def train_ep():\n",
    "    cnt = 0\n",
    "    for train in tqdm(get_data(10)):\n",
    "        test_ner.zero_grad()\n",
    "        \n",
    "        if common.IN_JUPYTER or common.IN_TRAVIS: \n",
    "            # avoid overtime\n",
    "#             if cnt > 10:\n",
    "#                 break\n",
    "            pass\n",
    "        cnt += 1\n",
    "        \n",
    "        train_X, train_Y = train\n",
    "        train_Y = onehot(train_Y, num_label)\n",
    "        train_Y = torch.Tensor(train_Y)\n",
    "        train_X = torch.LongTensor(train_X)\n",
    "        train_X = train_X.cuda()\n",
    "        train_Y = train_Y.cuda()\n",
    "\n",
    "        outputs = test_ner(train_X, train_Y)\n",
    "    #     print(outputs.shape, train_Y.shape)\n",
    "    #     loss = nn.CrossEntropyLoss(outputs, train_Y)\n",
    "        loss = outputs.sum()\n",
    "        loss.backward()\n",
    "        with torch.no_grad() :\n",
    "            for p in test_ner.parameters():\n",
    "                p.data.add_(-lr, p.grad.data)\n",
    "                \n",
    "    return loss\n",
    "for ep in tqdm(range(10)):\n",
    "    print(train_ep())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T11:42:31.944220Z",
     "start_time": "2020-03-12T11:42:30.209622Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted CRF.ipynb to ..\\exp\\CRF.py\n",
      "Converted CRF.ipynb to ..\\test\\test_CRF.py\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "common.save_and_export_notebook('CRF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:13:34.913571Z",
     "start_time": "2020-03-12T15:13:34.561456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([2390, 176, 30])\n",
      "<class 'torch.Tensor'> torch.Size([2390, 176])\n",
      "<class 'torch.Tensor'> torch.Size([2390, 176, 30])\n",
      "<class 'torch.Tensor'> torch.Size([2390, 1])\n",
      "<class 'torch.Tensor'> torch.Size([2390, 175, 30, 30])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([30, 30])\n",
      "<class 'torch.Tensor'> torch.Size([2, 2])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1794, 64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([30, 32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([30])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([30, 30])\n",
      "<class 'torch.Tensor'> torch.Size([2, 68, 30])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1794, 64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([128])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([30, 32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([30])\n",
      "<class 'torch.Tensor'> torch.Size([2380, 2380])\n",
      "<class 'torch.Tensor'> torch.Size([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zengjianjun/anaconda3/envs/py3torch/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gc\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "            print(type(obj), obj.size())\n",
    "    except: pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3torch)",
   "language": "python",
   "name": "py3torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
