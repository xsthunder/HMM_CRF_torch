
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: ./nb/CRF.ipynb

import sys
if __name__ == '__main__': sys.path.append('..')
import exp.common as common
from pprint import pprint
def pj(*args, **kargs):
    if common.IN_JUPYTER:
        pprint(*args, **kargs)

import operator

import torch
from torch import nn
def onehot(y, num):
    """
    y: shape (batch_size, max_seq_len)
    """
    assert len(y.shape) == 2, y.shape
    eye = np.eye(num)
    return eye[y]

def get_shift_mask(labels):
    """
    labels: (batch_size, max_seq_len, num_label) in onehot all element should be 1/0
    turn num_labels into matrix of (num_label, num_label) where m[ y[i] ][ y[i+1] ] = 1, 0 for else
    return (batch_size, max_seq_len, num_label, num_label)
    """
    labels1 = labels[:, :-1, ] # y[i]

    labels2 = labels[:, 1:] # y[i + 1]

    labels1 = labels1[:, :, :, None] # as ç³»æ•°, row indexer
    labels2 = labels2[:, :, None, :] # as row, col indexer

    shift_mask = labels1 * labels2
    return shift_mask

import math
# ğŸ‘´çš„CRF
class CRF(nn.Module):
    def __init__(self):
        super().__init__()
        # å…ˆä¸è€ƒè™‘paddingæ ‡ç­¾çš„é—®é¢˜
        # å…ˆä¸è€ƒè™‘maskçš„é—®é¢˜
        self.trans = nn.Parameter(torch.Tensor(num_label, num_label))
        nn.init.kaiming_uniform_(self.trans, a=math.sqrt(5))

    def path_score(self, inputs, labels, trans = None):
        """
        score of h(y[i]) ground-truch y[i] plus its g[y[i]][y[i+1]], inputs for h, trans for g
        inputs.size() # batch_size, max_seq_len, num_label
        trans.size() # num_label, num_label
        labels.size() #batch_size, max_seq_len, num_label
        """
        trans = self.trans if trans is None else trans

        sum_h_score = inputs * labels # batch_size, max_seq_len, num_label
        sum_h_score = sum_h_score.sum(-1, ) # batch_size, max_seq_len
        sum_h_score = sum_h_score.sum(-1, keepdim = True) # batch_size, 1

        mask = get_shift_mask(labels)
        sum_g_score = mask * trans[None, None]
        sum_g_score = sum_g_score.sum((-1, -2)) # batch_size, max_seq_len
        sum_g_score = sum_g_score.sum((-1), keepdim = True) # batch_size, 1
        path_score = sum_g_score + sum_h_score
        path_score.shape # batc_size, 1
        return path_score


    def forward(self, inputs, labels):
        """
        inputs: (batch_size, max_seq_len, label_num) embed with latent dim label_nun
        labels: (batch_size, max_seq_len, label_num) ground-truth label in onehot
        return: score
       """
        path_score = self.path_score(inputs, labels)

        return inputs
        pass